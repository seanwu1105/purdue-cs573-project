{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./assets/preprocessed.csv', encoding='ISO-8859-1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "classifiers = (\n",
    "    KNeighborsClassifier(n_neighbors=10),\n",
    "    GaussianNB(),\n",
    "    RandomForestClassifier(max_depth=20, n_estimators=1000),\n",
    "    SVC(),\n",
    "    XGBClassifier(use_label_encoder=False)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from embed_bag_of_words import load_embedded_bag_of_words\n",
    "from embed_tf_idf import load_embedded_tf_idf\n",
    "from embed_word2vec import load_embedded_word2vec\n",
    "from embed_glove import load_embedded_glove\n",
    "\n",
    "embeddings = {'bag of words': load_embedded_bag_of_words,\n",
    "              'tf idf': load_embedded_tf_idf,\n",
    "              'word2vec': load_embedded_word2vec,\n",
    "              'glove': load_embedded_glove}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df['label'].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag of words\n",
      "KNeighborsClassifier test accuracy: 0.286\n",
      "GaussianNB test accuracy: 0.444\n",
      "RandomForestClassifier test accuracy: 0.607\n",
      "SVC test accuracy: 0.782\n",
      "[04:01:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier test accuracy: 0.769\n",
      "\n",
      "tf idf\n",
      "KNeighborsClassifier test accuracy: 0.204\n",
      "GaussianNB test accuracy: 0.442\n",
      "RandomForestClassifier test accuracy: 0.602\n",
      "SVC test accuracy: 0.792\n",
      "[09:07:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier test accuracy: 0.757\n",
      "\n",
      "word2vec\n",
      "KNeighborsClassifier test accuracy: 0.590\n",
      "GaussianNB test accuracy: 0.509\n",
      "RandomForestClassifier test accuracy: 0.662\n",
      "SVC test accuracy: 0.703\n",
      "[09:19:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier test accuracy: 0.684\n",
      "\n",
      "glove\n",
      "KNeighborsClassifier test accuracy: 0.589\n",
      "GaussianNB test accuracy: 0.552\n",
      "RandomForestClassifier test accuracy: 0.641\n",
      "SVC test accuracy: 0.676\n",
      "[09:23:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier test accuracy: 0.662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, load_func in embeddings:\n",
    "    print(name)\n",
    "    data = load_func()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, labels,\n",
    "                                                        test_size=0.2,\n",
    "                                                        random_state=42)\n",
    "    for classifier in classifiers:\n",
    "        classifier.n_jobs = -1\n",
    "        classifier.fit(X_train, y_train)\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        acc_test = accuracy_score(y_test, y_pred)\n",
    "        print(f'{classifier.__class__.__name__} test accuracy: {acc_test:.3f}')\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4b5a55ad0ced575594b0c43a826a403fede8198b3c7db7b1b0f97f980daef42b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('.venv': poetry)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
