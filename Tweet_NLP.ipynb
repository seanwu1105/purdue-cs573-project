{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import sys\n",
    "import nltk\n",
    "\n",
    "# sklearn related\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, precision_recall_curve, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re \n",
    "import nltk \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "\n",
    "\n",
    "from io import StringIO\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./tweets/Corona_NLP_train.csv\", encoding=\"latin1\")\n",
    "test = pd.read_csv(\"./tweets/Corona_NLP_test.csv\", encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classes_def(x):\n",
    "    if x ==  \"Extremely Positive\":\n",
    "        return \"2\"\n",
    "    elif x == \"Extremely Negative\":\n",
    "        return \"0\"\n",
    "    elif x == \"Negative\":\n",
    "        return \"0\"\n",
    "    elif x ==  \"Positive\":\n",
    "        return \"2\"\n",
    "    else:\n",
    "        return \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text'] = train.OriginalTweet\n",
    "train[\"text\"] = train[\"text\"].astype(str)\n",
    "\n",
    "test['text'] = test.OriginalTweet\n",
    "test[\"text\"] = test[\"text\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['label']=train['Sentiment'].apply(lambda x:classes_def(x))\n",
    "test['label']=test['Sentiment'].apply(lambda x:classes_def(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(text):\n",
    "    url_remove = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_remove.sub(r'', text)\n",
    "train['text_new']=train['text'].apply(lambda x:remove_urls(x))\n",
    "test['text_new']=test['text'].apply(lambda x:remove_urls(x))\n",
    "\n",
    "def remove_html(text):\n",
    "    html=re.compile(r'<.*?>')\n",
    "    return html.sub(r'',text)\n",
    "train['text']=train['text_new'].apply(lambda x:remove_html(x))\n",
    "test['text']=test['text_new'].apply(lambda x:remove_html(x))\n",
    "\n",
    "# Lower casing\n",
    "def lower(text):\n",
    "    low_text= text.lower()\n",
    "    return low_text\n",
    "train['text_new']=train['text'].apply(lambda x:lower(x))\n",
    "test['text_new']=test['text'].apply(lambda x:lower(x))\n",
    "\n",
    "\n",
    "# Number removal\n",
    "def remove_num(text):\n",
    "    remove= re.sub(r'\\d+', '', text)\n",
    "    return remove\n",
    "train['text']=train['text_new'].apply(lambda x:remove_num(x))\n",
    "test['text']=test['text_new'].apply(lambda x:remove_num(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove stopwords & Punctuations\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\", \".join(stopwords.words('english'))\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def punct_remove(text):\n",
    "    punct = re.sub(r\"[^\\w\\s\\d]\",\"\", text)\n",
    "    return punct\n",
    "train['text_new']=train['text'].apply(lambda x:punct_remove(x))\n",
    "test['text_new']=test['text'].apply(lambda x:punct_remove(x))\n",
    "\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"custom function to remove the stopwords\"\"\"\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "train['text']=train['text_new'].apply(lambda x:remove_stopwords(x))\n",
    "test['text']=test['text_new'].apply(lambda x:remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove mentions and hashtags\n",
    "def remove_mention(x):\n",
    "    text=re.sub(r'@\\w+','',x)\n",
    "    return text\n",
    "train['text_new']=train['text'].apply(lambda x:remove_mention(x))\n",
    "test['text_new']=test['text'].apply(lambda x:remove_mention(x))\n",
    "\n",
    "def remove_hash(x):\n",
    "    text=re.sub(r'#\\w+','',x)\n",
    "    return text\n",
    "train['text']=train['text_new'].apply(lambda x:remove_hash(x))\n",
    "test['text']=test['text_new'].apply(lambda x:remove_hash(x))\n",
    "\n",
    "#Remove extra white space left while removing stuff\n",
    "def remove_space(text):\n",
    "    space_remove = re.sub(r\"\\s+\",\" \",text).strip()\n",
    "    return space_remove\n",
    "train['text_new']=train['text'].apply(lambda x:remove_space(x))\n",
    "test['text_new']=test['text'].apply(lambda x:remove_space(x))\n",
    "test = test.drop(columns=['text_new'])\n",
    "train = train.drop(columns=['text_new'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 4000\n",
    "pd.options.display.max_seq_items = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw = train[\"text\"].tolist()\n",
    "y_train = train[\"label\"].tolist()\n",
    "X_test_raw = test[\"text\"].tolist()\n",
    "y_test = test[\"label\"].tolist()\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "#                                                     test_size=0.10,\n",
    "#                                                     random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://ithelp.ithome.com.tw/articles/10194633"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = {}\n",
    "f = open('glove.6B.100d.txt', encoding='utf8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    glove[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glove_to_vec(data, dim=100):\n",
    "    ret = np.zeros((len(data), dim))\n",
    "    invalid = 0\n",
    "    for n in range(len(data)):\n",
    "        tweet = data[n]\n",
    "        tokens = tweet.split()\n",
    "        vecs = []\n",
    "        for word in tokens:\n",
    "            try:\n",
    "                # throws KeyError if word not found\n",
    "                vecs.append(glove[word])\n",
    "            except KeyError:\n",
    "                pass\n",
    "        if len(vecs) > 0:\n",
    "            vecs = np.array(vecs)\n",
    "            ret[n] = vecs.mean(axis=0)\n",
    "        else:\n",
    "            invalid+=1\n",
    "    return ret\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, IsolationForest,VotingClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn import tree\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grid_model(classifier, param_grid):\n",
    "    cv = StratifiedShuffleSplit(n_splits=2, test_size=0.1)\n",
    "    grid_model = GridSearchCV(classifier, param_grid=param_grid, cv=cv, n_jobs=-1, verbose=1, scoring='accuracy')\n",
    "    return grid_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(grid_model, predicted_test, test_label, predicted_train, train_label, file_name, \n",
    "           decision_function, clf_name=\"Classifier\"):\n",
    "    print(\"Results for \", clf_name, \": \")\n",
    "    print()\n",
    "    print(\"Best parameters are %s\" % (grid_model.best_params_))\n",
    "    acc_train = accuracy_score(train_label, predicted_train)\n",
    "    acc_test = accuracy_score(test_label, predicted_test)\n",
    "    print(\"Train Accuracy:  %0.3f\" % (acc_train))\n",
    "    print(\"Validation Accuracy:   %0.3f\" % (grid_model.best_score_))\n",
    "    print(\"Test Accuracy   %0.3f\" % (acc_test ))\n",
    "\n",
    "\n",
    "    print(\"Mean training time: %f\" % (np.mean(grid_model.cv_results_['mean_fit_time'], axis=0)) )\n",
    "    print(\"Mean test time: %f\" % (np.mean(grid_model.cv_results_['mean_score_time'], axis=0)) )\n",
    "    \n",
    "    # confusion matrix\n",
    "    print(\"Confusion matrix / precision recall scores\")\n",
    "    print ( confusion_matrix(test_label, predicted_test) )\n",
    "    print ( classification_report(test_label, predicted_test) )\n",
    "    \n",
    "    \n",
    "    f = open(file_name+'.txt','w')\n",
    "    f.write(\"Best parameters are %s\\n\"% (grid_model.best_params_))\n",
    "    f.write(\"Train Accuracy: %0.3f\\n\" % (acc_train))\n",
    "    f.write(\"Validation Accuracy: %0.3f\\n\" % (grid_model.best_score_))\n",
    "    f.write(\"Test Accuracy: %0.3f\\n\" % (acc_test ))\n",
    "    f.write(str(confusion_matrix(test_label, predicted_test)) + \"\\n\")\n",
    "    f.write(str(classification_report(test_label, predicted_test)) + \"\\n\\n\")\n",
    "    f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "menyrbie phil_gahan chrisitv\n",
      "abidsuleri shiffa_zy coronavirusinpakistan\n",
      "\n",
      "\n",
      "coronavirusbetternetizensmockerymodemelaniastarpandemicadswatchshopstaffpushelderlymanoutsidestorelondonpubliclosingtempercovidpriyanka chopraurgefanstockupjoylovegrocerypandemic\n",
      "usimposenewiranlinksanctionsentitiescovidconsumergoodgiantfaceboycottcall raisingsoaphandsanitiserpricescovidrbibuyblnworthgovtsecuritiesstabilisefinancialmarket\n",
      "ynetalerts\n",
      "\n",
      "coronacrisis coronavirusuk staysafe\n",
      "coronacrisis\n",
      "\n",
      "\n",
      "âcovidâ âgt covid_ covid springnews\n",
      "covid_\n",
      "\n",
      "germanymerkelquarantinesupermarketmeetingcovidinfecteddoctorussenatorrand paultestpositivejeffrey epsteinspentthousandsdollarsfundingallegedpimpghislainemaxwelldie\n",
      "\n",
      "covidlockdowndontpanicthereismorefooddeputyagricminister\n",
      "brazilhealthofficialconfirmfirstindigenouscoronaviruscaseamazonchiefbezossaydonatingfoodcharitycovidpandemictrumpcampaigndemandjeffsessioncampaignenddelusionalinvokingtiespresidentturkey\n",
      "\n",
      "\n",
      "\n",
      "nhk_news\n",
      "kedaceramicsghanaandsundainternationaldealersinfastmovingconsumergoodshavedonatedfivehundredthousandghanacedisghc\n",
      "devestating\n",
      "\n",
      "âwhat creatureâ\n",
      "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  6.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for  RandomForest : \n",
      "\n",
      "The best parameters are {'max_depth': 20, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "The Train Accuracy  0.997\n",
      "The Validation Accuracy   0.653\n",
      "The Test Accuracy   0.612\n",
      "Mean training time: 53.676893\n",
      "Mean test time: 0.254438\n",
      "Confusion matrix / precision recall scores\n",
      "[[ 998   64  571]\n",
      " [ 197  164  258]\n",
      " [ 333   52 1161]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.61      0.63      1633\n",
      "           1       0.59      0.26      0.36       619\n",
      "           2       0.58      0.75      0.66      1546\n",
      "\n",
      "    accuracy                           0.61      3798\n",
      "   macro avg       0.61      0.54      0.55      3798\n",
      "weighted avg       0.61      0.61      0.60      3798\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# stock_with_absolute, predict 1 day trend \n",
    "rfc = RandomForestClassifier() # classifier\n",
    "max_depth = [2, 4, 8, 10, 20]\n",
    "n_estimators = [100, 500]#, 500, 1000]\n",
    "max_features = [2 ,'sqrt']\n",
    "# min_samples_split = [None, 10, 50]\n",
    "\n",
    "# param to grid search\n",
    "param_grid = dict(max_depth=max_depth, n_estimators=n_estimators, max_features=max_features)\n",
    "\n",
    "X_train = glove_to_vec(X_train_raw)\n",
    "X_test = glove_to_vec(X_test_raw)\n",
    "\n",
    "rfc_model = create_grid_model(rfc, param_grid)\n",
    "rfc_model.fit(X_train, y_train)\n",
    "\n",
    "predicted_test = rfc_model.predict(X_test)\n",
    "predicted_train = rfc_model.predict(X_train)\n",
    "decision_function = rfc_model.predict_proba(X_test)\n",
    "\n",
    "evaluation(rfc_model, predicted_test, y_test, predicted_train, y_train, \n",
    "       \"./results/rfc\", decision_function, clf_name=\"RandomForest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for  RandomForest : \n",
      "\n",
      "The best parameters are {'max_depth': 10, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "The Train Accuracy  0.725\n",
      "The Validation Accuracy   0.616\n",
      "The Test Accuracy   0.594\n",
      "The mean training time of 104.324430\n",
      "The mean test time of 0.417043\n",
      "confusion matrix / precision recall scores\n",
      "[[ 934   45  654]\n",
      " [ 194  122  303]\n",
      " [ 314   31 1201]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.57      0.61      1633\n",
      "           1       0.62      0.20      0.30       619\n",
      "           2       0.56      0.78      0.65      1546\n",
      "\n",
      "    accuracy                           0.59      3798\n",
      "   macro avg       0.61      0.52      0.52      3798\n",
      "weighted avg       0.61      0.59      0.57      3798\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation(rfc_model, predicted_test, y_test, predicted_train, y_train, \n",
    "       \"./results/rfc\", decision_function, clf_name=\"RandomForest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
